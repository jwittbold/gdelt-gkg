
# configure GDELT GKG Pipeline 

[FS]
# To execute on local file system set prefix equal to: 'file://'
# To execute on local hadoop set prefix equal to empty striing: ''
# To execute on Databricks set prefix equal to: '/mnt'
PREFIX = 'file://'


[SCRAPER]
# Enter date as YEAR-MONTH-DAY format, e.g., 2021-09-01
# START_DATE corresponds to the date from which you would like to download GDELT GKG records.
# END_DATE by default is set to 'now' to download all available records. 
# END_DATE can be set to any date later than START_DATE in order to download a limited range of dates, format, e.g., 2021-09-02
# END_DATE will return files for END_DATE - 15 minutes, not inclusive, so if END_DATE = 2021-09-02, it will download all GKG FILE up 2021-09-01 23:45:00
# FROM_LAST if set to 'true' will use the last GKG record timestamp as start date. If 'false' it will use START_DATE
# START_DATE = '2021-10-21'
START_DATE = '2022-01-25'
END_DATE = 'now'
FROM_LAST = true
DOWNLOAD_METRICS = '/Users/jackwittbold/Desktop/gdelt_data/TEST_RUN_ONE_DAY/download_metrics'


[AZURE]
PREFIX = 'wasbs://'
CONTAINER = 'gkg_data'
STORAGE_ACC = 'gdelt'
SUFFIX = '.blob.core.windows.net'


[BATCH]
# PERIOD set to 'daily', 'hourly', or '15min' to control how GKG files are written out.
# CHOOSE ONE 
# 'daily' -- will repartion to create (5) parquet files ~ 120MB each. Avoids small file problem.
# 'hourly' -- will coalesce to create (1) parquet file for each batch run. Smaller files.
# '15min' -- will coalesce to create (1) parquet file for each batch run. Smaller files.
PERIOD = 'daily'


[ETL]
# DOWNLOAD_PATH and IN_PATH should point to the same directory. EXTRACT_PATH can be the same as 
# DOWNLOAD_PATH or different. It simply holds GKG zip files while being extracted, zip files are then deleted.
# PIPELINE METRICS directory is created once execute_etl.py is run.
# OUT_PATH will be where  
  [ETL.PATHS]
    DOWNLOAD_PATH = '/Users/jackwittbold/Desktop/gdelt_data/TEST_RUN_ONE_DAY/raw_gkg'
    EXTRACT_PATH = '/Users/jackwittbold/Desktop/gdelt_data/TEST_RUN_ONE_DAY/raw_gkg'
    PIPELINE_METRICS = '/Users/jackwittbold/Desktop/gdelt_data/TEST_RUN_ONE_DAY/pipeline_metrics'
    RAW_IN = '/Users/jackwittbold/Desktop/gdelt_data/TEST_RUN_ONE_DAY/raw_gkg'
    TRANSFORMED_OUT = '/Users/jackwittbold/Desktop/gdelt_data/TEST_RUN_ONE_DAY/transformed_gkg'
    

[FEEDS]
# GDELT Global Knowledge Graph -- Last four hyperlinks on URL below
# https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/
MASTER = ['http://data.gdeltproject.org/gdeltv2/masterfilelist.txt',
        'http://data.gdeltproject.org/gdeltv2/masterfilelist-translation.txt']
LAST_UPDATE = ['http://data.gdeltproject.org/gdeltv2/lastupdate.txt',
              'http://data.gdeltproject.org/gdeltv2/lastupdate-translation.txt']